{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab06.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kimsuazo/DeepLearningStuff/blob/master/RNN's.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNgvzqC1IBjH",
        "colab_type": "text"
      },
      "source": [
        "# Recurrent Neural Networks\n",
        "\n",
        "## Lab credit\n",
        "Lab created by [Santiago Pascual](https://scholar.google.es/citations?user=7cVOyh0AAAAJ&hl=ca) and [Xavier Giro-i-Nieto](https://imatge.upc.edu/web/people/xavier-giro) for the [Postgraduate course in artificial intelligence with deep learning](https://www.talent.upc.edu/ing/estudis/formacio/curs/310400/postgrau-artificial-intelligence-deep-learning/) in [UPC School](https://www.talent.upc.edu/ing/) (2019).\n",
        "\n",
        "## Slides\n",
        "Related [slides](https://github.com/telecombcn-dl/dlai-2019/raw/master/slides/dlai_2019_d06l1_rnn.pdf) by [Marta R. Costa-jussà](https://scholar.google.com/citations?user=ESqQ7FoAAAAJ&hl=ca&oi=ao) from [Deep Learning for Artificial Intelligence](https://telecombcn-dl.github.io/dlai-2019/) (UPC TelecomBCN 2018), and [slides](https://github.com/telecombcn-dl/2018-dlmm/raw/master/D1L06_RNN.pdf) from [Xavier Giro-i-Nieto](https://imatge.upc.edu/web/people/xavier-giro) from [Deep Learning for Multimedia](https://telecombcn-dl.github.io/2018-dlmm/) (Dublin City University 2018).\n",
        "\n",
        "\n",
        "## Video lectures\n",
        "\n",
        "Related [video (basic)](https://www.youtube.com/watch?v=nVY3RyYYfH8) & [video (advanced)](https://www.youtube.com/watch?v=9BqhYeCrxRk) by [Santiago Pascual](https://scholar.google.es/citations?user=7cVOyh0AAAAJ&hl=ca) from [Deep Learning for Speech and Language](https://telecombcn-dl.github.io/2017-dlsl/) (UPC TelecomBCN 2017), and [video](https://www.youtube.com/watch?v=N3DzDnzL19U) by [Marta R. Costa-jussà](https://scholar.google.com/citations?user=ESqQ7FoAAAAJ&hl=ca&oi=ao) from [Deep Learning for Artificial Intelligence](https://telecombcn-dl.github.io/dlai-2019/) (UPC TelecomBCN 2019)\n",
        "\n",
        "\n",
        "![Santiago Pascual](https://telecombcn-dl.github.io/dlai-2019/img/instructors/SantiPascual.jpg)\n",
        "![Marta R. Costa-jussà](https://telecombcn-dl.github.io/dlai-2019/img/instructors/MartaRuiz.jpg)\n",
        "![Xavier Giro-i-Nieto](https://telecombcn-dl.github.io/dlai-2019/img/instructors/XavierGiro.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqBBz46awSAh",
        "colab_type": "text"
      },
      "source": [
        "# The Fault in Our Time\n",
        "\n",
        "This lab session introduces our beloved friends, the [recurrent neural networks (RNNs)](https://en.wikipedia.org/wiki/Recurrent_neural_network). Concretely, the topology we will be seeing is the Elman type, nowadays widely known plainly as RNN. Recurrent neural networks are the super cool queens of sequences: they know about order in sequences. As a quick test for how important sequential context is, and to prove that it is also very important for you... **CAN YOU TELL THE SIXTH DIGIT OF YOUR MOBILE PHONE NUMBER? WHAT PROCESS ARE YOU FOLLOWING TO RECALL IT?** Exactly, you went straight from the beginning of the full sequence, hence this is how important sequences are to us too :)\n",
        "\n",
        "A fully connected layer is defined as:\n",
        "\n",
        "$\\boldsymbol{h}_t = \\tanh(\\boldsymbol{W}\\boldsymbol{x}_t + \\boldsymbol{b})$\n",
        "\n",
        "With \"only one\" (but super important) change we formulate the RNN:\n",
        "\n",
        "$\\boldsymbol{h}_t = \\tanh(\\boldsymbol{W}\\boldsymbol{x}_t + \\boldsymbol{U}\\boldsymbol{h}_{t-1} + \\boldsymbol{b})$\n",
        "\n",
        "Exactly, we added the matrix $\\boldsymbol{U}$ which is a set of connections among all the neurons from the hidden layers to themselves (hence a feedback)!\n",
        "\n",
        "This looks like the following, which is typically unrolled in time to show both flows of data, feed-forward ($\\boldsymbol{W}$) + time ($\\boldsymbol{U}$):\n",
        "\n",
        "![rnn image](https://image.slidesharecdn.com/dlcvd2l6recurrentneuralnetworks-160802094750/95/deep-learning-for-computer-vision-recurrent-neural-networks-upc-2016-16-638.jpg?cb=1470131837)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Bz3-4ys0BgA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's first import the typical stuff to play with deep nets\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "import matplotlib\n",
        "% matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from timeit import default_timer as timer\n",
        "\n",
        "torch.manual_seed(1)\n",
        "device = 'cpu'\n",
        "if torch.cuda.is_available():\n",
        "  device = 'cuda'\n",
        "  torch.cuda.manual_seed_all(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8YHdo2o0Ago",
        "colab_type": "text"
      },
      "source": [
        "### Exercise 1: Building a recurrent neural layer\n",
        "\n",
        "In the next cell, we will define our own unidirectional RNN layer. The class `MyUnidirectionalRNN` must make use of `nn.Linear` layers to make the feed-forward and time projections, and use the `nn.Parameter` class to build the biases. Please build the recurrent neural component with the addition of the recurrent connections.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpoEQQp2z_TX",
        "colab_type": "code",
        "outputId": "af8bef04-ee90-4cb4-d615-51b865d2d8e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "class MyUnidirectionalRNN(nn.Module):\n",
        "\n",
        "  def __init__(self, num_inputs, rnn_size=128):\n",
        "    super().__init__()\n",
        "\n",
        "    # Linear layers\n",
        "    # Define the input activation matrix W\n",
        "    self.W = nn.Linear(num_inputs, rnn_size, bias=False)\n",
        "    # TODO: Define the hidden activation matrix U\n",
        "    self.U = nn.Linear(rnn_size, rnn_size, bias = False)\n",
        "    \n",
        "    self.rnn_size = rnn_size\n",
        "    # Define the bias\n",
        "    self.b = nn.Parameter(torch.zeros(1, rnn_size))\n",
        "\n",
        "  def forward(self, x, state=None):\n",
        "    # Assuming x is of shape [batch_size, seq_len, num_feats]\n",
        "    xs = torch.chunk(x, x.shape[1], dim=1)\n",
        "    hts = []\n",
        "    if state is None:\n",
        "      state = self.init_state(x.shape[0])\n",
        "    for xt in xs:\n",
        "      # turn x[t] into shape [batch_size, num_feats] to be projected\n",
        "      xt = xt.squeeze(1)\n",
        "      ct = self.W(xt)\n",
        "      ct = ct + self.U(state)\n",
        "      state = ct + self.b\n",
        "      # give the temporal dimension back to h[t] to be cated\n",
        "      hts.append(state.unsqueeze(1))\n",
        "    hts = torch.cat(hts, dim=1)\n",
        "    return hts\n",
        "\n",
        "  def init_state(self, batch_size):\n",
        "    return torch.zeros(batch_size, self.rnn_size)\n",
        "\n",
        "# To correctly assess the answer, we build an example RNN with 10 inputs and 32 neurons\n",
        "rnn = MyUnidirectionalRNN(10, 32)\n",
        "# Then we will forward some random sequences, each of length 15\n",
        "xt = torch.randn(5, 15, 10)\n",
        "# The returned tensor will be h[t]\n",
        "ht = rnn(xt)\n",
        "assert ht.shape[0] == 5 and ht.shape[1] == 15 and ht.shape[2] == 32, \\\n",
        "'Something went wrong within the RNN :('\n",
        "print('Success! Output shape: {} sequences, each of length {}, each '\\\n",
        "      'token with {} dims'.format(ht.shape[0], ht.shape[1], ht.shape[2]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Success! Output shape: 5 sequences, each of length 15, each token with 32 dims\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THnEZ6UmPAJU",
        "colab_type": "text"
      },
      "source": [
        "### But Why Would You Do That?\n",
        "\n",
        "Congratz on finishing your first RNN definition! Now you should understand a bit more on the intrinsics of our sequential friends. But why would you define your own RNN? We didn't even operate with a GPU. We didn't even consider that possibility. So in the real world, we use PyTorch's `nn.RNN`, which allows for building a **stack of RNN layers directly**. Let's see some examples:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMYbxHB7EVYl",
        "colab_type": "code",
        "outputId": "048458cf-7eb5-4076-b16f-6b33cd323355",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# we will work with 10 input features\n",
        "NUM_INPUTS = 10\n",
        "# and sequences of length 25\n",
        "SEQ_LEN = 25\n",
        "# and 5 samples per batch\n",
        "BATCH_SIZE = 5 \n",
        "# and 128 neurons\n",
        "HIDDEN_SIZE = 128\n",
        "\n",
        "# The first RNN contains a single layer\n",
        "rnn1 = nn.RNN(NUM_INPUTS, HIDDEN_SIZE)\n",
        "print(rnn1)\n",
        "\n",
        "# Now let's build a random input tensor to forward through it\n",
        "xt = torch.randn(SEQ_LEN, BATCH_SIZE, NUM_INPUTS)\n",
        "ht, state = rnn1(xt)\n",
        "print('Output h[t] tensor shape: ', ht.shape)\n",
        "print('Output state tensor shape: ', state.shape)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RNN(10, 128)\n",
            "Output h[t] tensor shape:  torch.Size([25, 5, 128])\n",
            "Output state tensor shape:  torch.Size([1, 5, 128])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eg4c-TaLQ5Ag",
        "colab_type": "text"
      },
      "source": [
        "#### OK STOP IT HERE, We've got to talk\n",
        "\n",
        "> Indented block\n",
        "\n",
        "> Indented block\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Think about how many things are happening in the previous cell. First, we define some hyper-parameters to define the input tensor shape and the RNN size. Then, we build one RNN layer. Then, we build random data. Finally, we forward the random data, and what is returned? Why does the input tensor `x` have that shape? Why is the RNN returning 2 output values?\n",
        "\n",
        "**First answer:** The input data to an RNN can be shaped in 2 formats: `batch_first=True` and `batch_first=False`. As its name indicates, when it is `False`, the `batch_size` dimension is not the first but the second one. Then which is the first one? The `sequence_length`. If we do not specify anything, by default `batch_first=False`, so the tensor $\\boldsymbol{x}_t$ must have the dimensions: [`seq_len`, `batch_size`, `num_feats`]. We normally use `batch_first=True` to couple the RNN easily with other layers like the `nn.Linear` one.\n",
        "\n",
        "### Exercise 2\n",
        "\n",
        "Find the second answer on \"**Why is the RNN returning 2 output values?**\". Understand what is the `state` output and answer: \"**what does it contain?**\". Your source of knowledge is in the following URL, where the outputs description for the `RNN` module is given: https://pytorch.org/docs/stable/nn.html#torch.nn.RNN\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wAY1wWTT3pR",
        "colab_type": "text"
      },
      "source": [
        "Now we can continue defining some more examples of RNN layers as promised before"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lr-Iqe2LT2CJ",
        "colab_type": "code",
        "outputId": "0fa0f88a-b09b-4114-810d-20097b411ccb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "# 2 Layer RNN\n",
        "rnn2 = nn.RNN(NUM_INPUTS, HIDDEN_SIZE, num_layers=2)\n",
        "ht, state = rnn2(xt)\n",
        "print('RNN 2 layers >> ht shape: ', ht.shape)\n",
        "print('RNN 2 layers >> state shape: ', state.shape)\n",
        "\n",
        "# Batch Size first RNN\n",
        "xt_bf = torch.randn(BATCH_SIZE, SEQ_LEN, NUM_INPUTS)\n",
        "rnn3 = nn.RNN(NUM_INPUTS, HIDDEN_SIZE, num_layers=2, batch_first=True)\n",
        "ht, state = rnn3(xt_bf)\n",
        "print('RNN 2 layers, batch_first >> ht.shape: ', ht.shape)\n",
        "print('RNN 2 layers, batch_first >> state.shape: ', state.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RNN 2 layers >> ht shape:  torch.Size([25, 5, 128])\n",
            "RNN 2 layers >> state shape:  torch.Size([2, 5, 128])\n",
            "RNN 2 layers, batch_first >> ht.shape:  torch.Size([5, 25, 128])\n",
            "RNN 2 layers, batch_first >> state.shape:  torch.Size([2, 5, 128])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfRkpNiOUwxA",
        "colab_type": "text"
      },
      "source": [
        "### Exercise 3.1\n",
        "Build a **single bidirectional RNN layer** by completing the TODO in the code \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGC9dA8iVBnJ",
        "colab_type": "code",
        "outputId": "b8c0c3ef-eb63-4d7e-f21f-beb7ec2d307d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# TODO: build the bidirectional RNN layer\n",
        "bi_rnn = nn.RNN(NUM_INPUTS, HIDDEN_SIZE, num_layers = 3, bidirectional = True, batch_first=True) \n",
        "\n",
        "# forward xt_bf\n",
        "bi_ht, bi_state = bi_rnn(xt_bf)\n",
        "print('Bidirectional RNN layer >> bi_ht.shape: ', bi_ht.shape)\n",
        "print('Bidirectional RNN layer >> bi_state.shape: ', bi_state.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bidirectional RNN layer >> bi_ht.shape:  torch.Size([5, 25, 256])\n",
            "Bidirectional RNN layer >> bi_state.shape:  torch.Size([6, 5, 128])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KO_2RZhmKIj8",
        "colab_type": "text"
      },
      "source": [
        "### Exercise 3.2\n",
        "What is the output $\\boldsymbol{h}_t$ shape and why?\n",
        "\n",
        "### Exercise 3.3\n",
        "What is the output `state` shape and why?."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgKP_9eKTQcp",
        "colab_type": "text"
      },
      "source": [
        "### Hold The Gates! A Recurrent Re-Evolution\n",
        "\n",
        "You've surely heard about the `LSTM` or the `GRU`, two practically sibling recurrent models. Well those are the actual RNNs you will use in your everyday. Why? Because they:\n",
        "1. Improve the memory capacity of the RNN.\n",
        "2. Improve the gradient flow of vanilla RNNs thanks to the learnable gate mechanisms.\n",
        "\n",
        "An LSTM or GRU cell is a composition of different neurons working jointly, and the whole thing replaces a single RNN neuron. The RNN cell (with one $\\tanh$ neuron), the LSTM cell and the GRU cell are depicted in the following figure from [this article](https://www.google.com/url?sa=i&rct=j&q=&esrc=s&source=images&cd=&cad=rja&uact=8&ved=2ahUKEwiMiPbfoPHlAhUQCxoKHW9qA04Qjhx6BAgBEAI&url=http%3A%2F%2Fdprogrammer.org%2Frnn-lstm-gru&psig=AOvVaw3mU76KRvFfY9WiOF4N12ex&ust=1574080203478260):\n",
        "\n",
        "![lstm](http://dprogrammer.org/wp-content/uploads/2019/04/RNN-vs-LSTM-vs-GRU-1200x361.png)\n",
        "\n",
        "Now check that out. In the case of the LSTM, we have **two signals flowing in time** apart from the feed-forward input per time-step: $\\boldsymbol{c}_t$ and $\\boldsymbol{h}_t$. The first one is called the cumulative cell state. It basically will add everything it is \"allowed to see\" from the input, and will forget portions of it. This is unbounded. On the other hand, the output cell state $\\boldsymbol{h}_t$ will be the final layer activation (what is allowed to come out of it). This is bounded [-1, 1]."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WhMLsykdUEq",
        "colab_type": "text"
      },
      "source": [
        "### Exercise 4: An LSTM Character-based Language Model\n",
        "\n",
        "In this final exercise we will train a language model that will work at the character level. This is, a neural network based on an RNN architecture that will complete language (textual) sequences.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAlNXik7TlRe",
        "colab_type": "text"
      },
      "source": [
        "Our dataset will be composed of scripts from the *Friends* TV show.\n",
        "\n",
        "1. Download the Friends episode 1 trainset from [here](https://github.com/telecombcn-dl/dlai-2019/raw/master/labs/episode1_english.txt).\n",
        "2. Upload it to the Google colab in the handler that appears in the following cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3rZzWbgeOck",
        "colab_type": "code",
        "outputId": "0122ae3a-b640-4ad2-e3a2-cb97b29377d4",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 82
        }
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4f95fe5c-8d73-491b-ba64-3728ddb2899a\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-4f95fe5c-8d73-491b-ba64-3728ddb2899a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving friends.txt to friends.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiZtfpgKdZxR",
        "colab_type": "code",
        "outputId": "11636133-305f-4138-e389-36dc22221912",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def prepare_sequence(seq, char2idx, onehot=True):\n",
        "    # convert sequence of words to indices\n",
        "    idxs = [char2idx[c] for c in seq]\n",
        "    idxs = torch.tensor(idxs, dtype=torch.long)\n",
        "    if onehot:\n",
        "      # conver to onehot (if input to network)\n",
        "      ohs = F.one_hot(idxs, len(char2idx)).float()\n",
        "      return ohs\n",
        "    else:\n",
        "      return idxs\n",
        "\n",
        "with open('friends.txt', 'r') as txt_f:\n",
        "  training_data = [l.rstrip() for l in txt_f if l.rstrip() != '']\n",
        "\n",
        "# merge the training data into one big text line\n",
        "training_data = '$'.join(training_data)\n",
        "\n",
        "# Assign a unique ID to each different character found in the training set\n",
        "char2idx = {}\n",
        "for c in training_data:\n",
        "    if c not in char2idx:\n",
        "            char2idx[c] = len(char2idx)\n",
        "idx2char = dict((v, k) for k, v in char2idx.items())\n",
        "VOCAB_SIZE = len(char2idx)\n",
        "RNN_SIZE = 1024\n",
        "MLP_SIZE = 2048\n",
        "SEQ_LEN = 50\n",
        "print('Number of found vocabulary tokens: ', VOCAB_SIZE)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of found vocabulary tokens:  67\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ehk_6JNIkZOs",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "##### Exercise 4.1\n",
        "* What is the amount of outputs needed by the character prediction model?\n",
        "\n",
        "##### Exercise 4.2\n",
        "* What is the proper activation to plug on top of the MLP (if any)? (Note that we use `NLLLoss` later on).\n",
        "\n",
        "##### Exercise 4.3\n",
        "* Finish the definition of the `CharLSTM` model to include a `nn.LSTM` layer, with `batch_first=True`, `vocab_size` inputs and `rnn_size` cells, and an MLP that projects the `rnn_size` to `mlp_size` with one `ReLU` hidden layer and then to the appropriate amount of outputs. Put a `Dropout(0.4)` after the `ReLU`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mNZENlUfY6a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CharLSTM(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, rnn_size, mlp_size):\n",
        "        super().__init__()\n",
        "        self.rnn_size = rnn_size \n",
        "\n",
        "        # TODO:\n",
        "        self.lstm=nn.LSTM(vocab_size, rnn_size, batch_first = True)\n",
        "\n",
        "        self.dout = nn.Dropout(0.4)\n",
        "\n",
        "        # TODOs:\n",
        "        # An MLP with a hidden layer of mlp_size neurons that maps from the RNN \n",
        "        # hidden state space to the output space of vocab_size\n",
        "        self.mlp = nn.Sequential(\n",
        "          nn.Linear(rnn_size, mlp_size,), # Linear layer\n",
        "          nn.ReLU(), # Activation function\n",
        "          nn.Dropout(0.4),\n",
        "          nn.Linear(mlp_size, vocab_size), # Linear layer\n",
        "          nn.LogSoftmax() # Output layer\n",
        "        )\n",
        "\n",
        "    def forward(self, sentence, state=None):\n",
        "        bsz, slen, vocab = sentence.shape\n",
        "        ht, state = self.lstm(sentence, state)\n",
        "        ht = self.dout(ht)\n",
        "        h = ht.contiguous().view(-1, self.rnn_size)\n",
        "        logprob = self.mlp(h)\n",
        "        return logprob, state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2w7aA-f8LihO",
        "colab_type": "text"
      },
      "source": [
        "Test how the model performs when using randomly initialized weights and biases:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4ko6BB6gdkI",
        "colab_type": "code",
        "outputId": "8e014314-a5ae-4e00-fe4c-03b52e03fb39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "# Let's build an example model and see what the scores are before training\n",
        "model = CharLSTM(VOCAB_SIZE, RNN_SIZE, MLP_SIZE)\n",
        "# This should output crap as it is not trained, so a fixed random tag for everything\n",
        "\n",
        "def gen_text(model, seed, char2idx, num_chars=150):\n",
        "  model.eval()\n",
        "  # Here we don't need to train, so the code is wrapped in torch.no_grad()\n",
        "  with torch.no_grad():\n",
        "      inputs = prepare_sequence(seed, char2idx)\n",
        "      # fill the RNN memory with the seed sentence\n",
        "      seed_pred, state = model(inputs.unsqueeze(0))\n",
        "      # now begin looping with feedback char by char from the last prediction\n",
        "      preds = seed\n",
        "      curr_pred = torch.topk(seed_pred[-1, :], k=1, dim=0)[1]\n",
        "      curr_pred = idx2char[curr_pred.item()]\n",
        "      preds += curr_pred\n",
        "      for t in range(num_chars):\n",
        "        curr_pred, state = model(prepare_sequence(curr_pred, char2idx).unsqueeze(0), state)\n",
        "        curr_pred = torch.topk(curr_pred[-1, :], k=1, dim=0)[1]\n",
        "        curr_pred = idx2char[curr_pred.item()]\n",
        "        if curr_pred == '$':\n",
        "          # special token to add newline char\n",
        "          preds += '\\n'\n",
        "        else:\n",
        "          preds += curr_pred\n",
        "      return preds\n",
        "\n",
        "      \n",
        "print(gen_text(model, 'Monica was ', char2idx))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Monica was AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ENS1_nViYFf",
        "colab_type": "code",
        "outputId": "3986bf39-9950-4f3e-d646-e66d8d7d4d50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "T = len(training_data)\n",
        "CHUNK_SIZE = T // BATCH_SIZE\n",
        "# let's first chunk the huge train sequence into BATCH_SIZE sub-sequences\n",
        "trainset = [training_data[beg_i:end_i] \\\n",
        "            for beg_i, end_i in zip(range(0, T - CHUNK_SIZE, CHUNK_SIZE),\n",
        "                                    range(CHUNK_SIZE, T, CHUNK_SIZE))]\n",
        "print('Original training string len: ', T)\n",
        "print('Sub-sequences len: ', CHUNK_SIZE)\n",
        "print(len(trainset[0]))\n",
        "\n",
        "# The way training works is the following:\n",
        "# at each batch sampling from the trainset, we pick a portion of sequences\n",
        "# continuous with a sliding window in time. Hence, each of the BATCH_SIZE sub-sequences\n",
        "# in batch b[i] will continue in batch b[i + 1] in the same position of the batch dimension.\n",
        "# This is called stateful sampling, where we train with consecutive windows of sequences\n",
        "# We broke the long string into BATCH_SIZE subsequence, so we introduced BATCH_SIZE - 1 \n",
        "# discontinuities... YES. But we can assume that each sub-sequence is continuous in a long\n",
        "# enough chunk so that those discontinuities are negligible."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original training string len:  23149\n",
            "Sub-sequences len:  361\n",
            "361\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_VVeGkjk5bs",
        "colab_type": "text"
      },
      "source": [
        "##### Exercise 4.4\n",
        "\n",
        "What is the length of the sliding window that will run over each of the training sub-sequences? NOTE: it is defined as a hyper-parameter above. How is this related to the backpropagation through time (BPTT)?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Rk_tr-Ikkjb",
        "colab_type": "code",
        "outputId": "a964ca3f-5eb9-4dae-82e8-866f07a1d72b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Let's now build a model to train with its optimizer and loss\n",
        "model = CharLSTM(VOCAB_SIZE, RNN_SIZE, MLP_SIZE)\n",
        "model.to(device)\n",
        "loss_function = nn.NLLLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "NUM_EPOCHS = 5000\n",
        "tr_loss = []\n",
        "state = None\n",
        "timer_beg = timer()\n",
        "print(len(trainset))\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  model.train()\n",
        "  # let's slide over our dataset\n",
        "  for beg_t, end_t in zip(range(0, CHUNK_SIZE - SEQ_LEN - 1, SEQ_LEN + 1),\n",
        "                          range(SEQ_LEN + 1, CHUNK_SIZE, SEQ_LEN + 1)):\n",
        "    # Step 1. Remember that Pytorch accumulates gradients.\n",
        "    # We need to clear them out before each instance\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    dataX = []\n",
        "    dataY = []\n",
        "    # Step 2. Get our inputs ready for the network, that is, turn them into\n",
        "    # Tensors of one-hot sequences. \n",
        "    for sent in trainset:\n",
        "      # chunk the sentence\n",
        "      chunk = sent[beg_t:end_t]\n",
        "      # get X and Y with a shift of 1\n",
        "      X = chunk[:-1]\n",
        "      Y = chunk[1:]\n",
        "      # convert each sequence to one-hots and labels respectively\n",
        "      X = prepare_sequence(X, char2idx)\n",
        "      Y = prepare_sequence(Y, char2idx, onehot=False)\n",
        "      dataX.append(X.unsqueeze(0)) # create batch-dim\n",
        "      dataY.append(Y.unsqueeze(0)) # create batch-dim\n",
        "      \n",
        "    dataX = torch.cat(dataX, dim=0).to(device)\n",
        "    dataY = torch.cat(dataY, dim=0).to(device)\n",
        "    \n",
        "\n",
        "    # Step 3. Run our forward pass.\n",
        "    # Forward through model and carry the previous state forward in time (statefulness)\n",
        "    y_, state = model(dataX, state)\n",
        "    print(y_.shape)\n",
        "    # detach the previous state graph to not backprop gradients further than the BPTT span\n",
        "    state = (state[0].detach(), # detach c[t]\n",
        "             state[1].detach()) # detach h[t]\n",
        "\n",
        "    # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "    #  calling optimizer.step()\n",
        "    loss = loss_function(y_, dataY.view(-1))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    tr_loss.append(loss.item())\n",
        "  timer_end = timer()  \n",
        "  if (epoch + 1) % 50 == 0:\n",
        "    # Generate a seed sentence to play around\n",
        "    model.to('cpu')\n",
        "    print('-' * 30) \n",
        "    print(gen_text(model, 'They ', char2idx))\n",
        "    print('-' * 30)\n",
        "    model.to(device)\n",
        "    print('Finished epoch {} in {:.1f} s: loss: {:.6f}'.format(epoch + 1, \n",
        "                                                               timer_end - timer_beg,\n",
        "                                                               np.mean(tr_loss[-10:])))\n",
        "  timer_beg = timer()\n",
        "\n",
        "plt.plot(tr_loss)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('NLLLoss')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "64\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "------------------------------\n",
            "They was a look it the with the were the were the sore the sore the sore the sore the sore the sore the sore the sore the sore the sore the sore the sore th\n",
            "------------------------------\n",
            "Finished epoch 50 in 0.7 s: loss: 1.573241\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "------------------------------\n",
            "They well my buck of nut fienither.\n",
            "Chandler: Oo hel starts to looking at the boor and something wrean'  Ros a leat ofal of the caffee, you mean a help dict\n",
            "------------------------------\n",
            "Finished epoch 100 in 0.7 s: loss: 0.237382\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n",
            "torch.Size([3200, 67])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-f258d48d8e5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0mtr_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m   \u001b[0mtimer_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m50\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyxWnNzCOAn8",
        "colab_type": "text"
      },
      "source": [
        "Now that the generator of characters is trained, we can ask it to predict the rest of a sentence that begins with `Professor `:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veKy0T5Cuqi1",
        "colab_type": "code",
        "outputId": "57a04e8f-1209-46e5-98cc-0b6981482df5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "print(gen_text(model.to('cpu'), 'Professor ', char2idx, 1000))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Professor shat her stopping on tate the goon.)\n",
            "Monica: So how you doint today? Did you need.\n",
            "Paul: (on the ine when you round John ks Pavo thankserellooks to the dintl tay) You gonna say? Paul's that? You gon for the watch.\n",
            "Monica: You and with the scarss to shat her coffhers out the door and oning finised you mered out of the gine Guy!\n",
            "Joey: What well maye I'm surping to me mearing a Spoon Do the words 'Billy, don't be a hero' mean't do you want hel this is.\n",
            "Paul: Well, you wish I cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut, cut,\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVRsFgHZa3f3",
        "colab_type": "text"
      },
      "source": [
        "### References\n",
        "\n",
        "[1] https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html"
      ]
    }
  ]
}